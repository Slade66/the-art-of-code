## 需求分析
	- **我们当前的痛点（为什么需要它？）：**
		- **告警风暴：**业务高峰期，告警太多，淹没真实问题。
		  collapsed:: true
			- **例子：**
				- 假设您的电商平台在晚上8点搞促销，这是业务高峰期。
				- 突然，一台核心的数据库服务器变慢了（这是真正的原因）。
				- **发生了什么？**
					- 数据库服务器开始告警（CPU高、响应慢）。
					  logseq.order-list-type:: number
					- 因为数据库慢，订单服务处理不了请求，开始告警（“处理超时”）。
					  logseq.order-list-type:: number
					- 因为订单服务慢，购物车服务也开始告警（“调用失败”）。
					  logseq.order-list-type:: number
					- 因为购物车慢，商品详情页也开始告警（“加载失败”）。
					  logseq.order-list-type:: number
					- ... 最终，前端监控也告警（“网站打不开”）。
					  logseq.order-list-type:: number
				- **痛点体现：**
					- 在2分钟内，您的告警平台收到了 500 条告警。
					- 真正的根源（数据库问题）只有 5 条，但它被其他 495 条“并发症”告警（订单、购物车...）彻底淹没了。
					- 这就是“告警风暴”，它让您无法第一时间找到那个最初倒下的“多米诺骨牌”。
		- **无效告警：**凌晨业务低谷时的正常波动，却频繁告警（“狼来了”）。
		- **配置僵化：**依赖“固定阈值”（如 >1000 就告警），无法适应业务的动态变化（如节假日、工作日）。
		  collapsed:: true
			- **例子：**
				- 假设您为“每分钟订单量”设置了一个**固定阈值**告警：`> 1000` 笔/分钟就告警（防止刷单） 和 `< 10` 笔/分钟就告警（防止系统宕机）。
				- **痛点体现（场景A：节假日）：**
					- **双十一大促**来了，订单量飙升到 `5000` 笔/分钟。
					- **结果：** 系统**疯狂告警** `> 1000`。但这是**正常的业务高峰**，不是问题。您被迫在双十一期间**手动关掉**这个告警。
				- **痛点体现（场景B：工作日）：**
					- **工作日凌晨3点**，这是业务低谷，正常订单量就是 `5` 笔/分钟。
					- **结果：** 系统**疯狂告警** `< 10`。但这是**正常的业务低谷**，不是宕机。您被迫每天凌晨都被“无效告警”吵醒。
				- **总结：**“固定阈值”无法自动适应“大促”和“凌晨”的场景差异。
		- **人力黑洞：**需要专人不断手动调整成百上千个指标的阈值。
		  collapsed:: true
			- **例子：**
				- 假设您的系统有 200 个微服务，每个服务有 10 个核心指标（CPU、内存、QPS、响应时间...），您总共需要管理 `200 * 10 = 2000` 个指标。
				- **痛点体现：**
					- **周一：** 运营团队说这周要做活动，A、B、C 服务的负载会上升。您（运维）必须**手动**找出这几十个指标，把它们的阈值**调高**。
					- **周三：** 研发团队发布了新版本，D、E 服务的性能优化了，它们的CPU和内存基线**永久性下降**了。您必须**手动**找出这些指标，把它们的阈值**调低**。
					- **周五：** 活动结束，您又得**手动**把 A、B、C 服务的阈值**调回去**。
				- **总结：**
					- 您（运维团队）没有在做“有价值”的自动化工作，而是变成了“阈值调整工”。
					- 您的绝大部分时间都花在了“追逐”业务变化上，这就是“人力黑洞”。如果忘了调整，就会导致“配置僵化”中的告警误报或漏报。
		- 基于以上原因，我们需要一个 AI 来分析告警，而智能告警平台没有 AI 分析功能，因此我们要集成数智慧得 AIOps 系统。
	- **智能告警平台的数据流转逻辑：**
		- Telegraf 把原始的指标数据推送给 Kafka，Flink 从 Kafka 中抓取数据然后推送给 Go Proxy，Go Proxy 再推送给数智慧让它进行分析，数智慧会产生告警和趋势：
			- Go Proxy 要轮询数智慧有没有产生告警，然后推送给智能告警平台展示。
			- 智能告警平台要从数智慧获取趋势。
	- **要集成的数智慧页面：**
		- 指标全局视图（趋势）。
		- 异常检测配置（配置产生告警的条件）。
		- 告警管理（当前告警）。
- ## 要解决的问题
	- 控制哪些 Flink 发来的指标要转发给数智慧（指标管理）。
	  collapsed:: true
		- `Nacos` 里那份 `metrics-allowlist.yaml`。
		- 需和武哥明确需推送的具体指标，避免全量数据推送（大量非必要的指标）。
	- 轮询数智慧的告警，有就推给智能告警系统。
	- 逆向分析数智慧 AIOps 系统的接口。
	  collapsed:: true
		- 在浏览器 F12 的 Network 页签下，每当你在页面上做一件事（点击某个按钮），就去观察新出现的 API 请求，然后立刻在 Apifox 中复现它，并把它保存在 Apifox 中。
		- 在过滤器 (Filter) 里，勾选 `Fetch/XHR`。这会帮你过滤掉所有图片、CSS、JS 等静态资源，只看 API 请求。
		- 当你把这三个页面的核心 API——获取趋势、CRUD 规则、查询告警——全部在 Apifox 里成功复现并调通后，你的阶段二就胜利完成了。
		- **如何鉴权：**
			- 随便点击一个页面功能，找到一个 API 请求，在它的 `Request Headers` (请求头) 里找到鉴权信息。
			- 这通常是一个 `Authorization: Bearer ...` (JWT Token) 或者是一个 `Cookie`。
			- **关键一步：**在 Apifox 中，把这个 `Authorization` 或 `Cookie` 配置到环境的 Header 里，这样 Apifox 才能模拟你“已登录”的身份去请求 API。
		- **使用 cURL 导入：**
			- 在 F12 Network 里，右键点击一个你分析的请求，选择 `Copy` -> `Copy as cURL (bash)`。
			- 在 Apifox 里，点击“导入”，粘贴 cURL。Apifox 会自动帮你填好 URL、Method、Header、Body。这是最快的方法，连 `Authorization` 都帮你带过来了。
	- Flink 的流量很大，会把 Go Proxy 推死，也会把数智慧推死。
	  collapsed:: true
		- **解决方案：**
			- **原则：**在 Flink 和 Go 服务之间，不能直接调用。不要让高吞吐量的流式系统直接调用一个 API 服务。
			- **转变架构：**Flink 不再直接调 Go Proxy，Go 服务从被动接受者变为 Kafka 的消费者，按照自己的节奏去 Kafka 消费数据，从而完全控制了对下游的压力。
			- **更进一步：把过滤的任务交给 Flink：**Flink 去配置中心拉取指标白名单，在处理 Kafka 的数据时，在内存中实时进行过滤，然后推送已过滤的数据到新的 Kafka Topic，Go Proxy 从新的 Topic 中读取数据。
			- **不能这么做：**Flink 的职责耦合。而且 Kafka 和 Flink 本身就削峰了，我们只能保证流量不被突然的无法预测的高峰冲垮，但是平时的正常流量都顶不住那就是数智慧的问题了。Flink 过滤过于占用内存。
			- **多维度降压：**
				- **减少对数智慧 API 的调用（批处理）：**Go 一次从 Kafka 拉取一大批数据进行处理，然后只发起一次 HTTP 请求，用一个网络请求提交批量数据。
				- **把指标粒度从秒级变为分钟级（窗口聚合）：**分析告警和预测趋势真的需要每秒的指标吗？用分钟级的指标能否预测出同样的效果？这样可以先用窗口函数对原始指标做聚合，降低发给数智慧的数据量。
					- **不能这么做：**但是降低数据的粒度，会导致告警的时间准确度下降，可能会延后产生告警信息。
				- **限流器：**Go 服务在每一次调用数智慧的 API 之前，都必须经过一个限流器，比如我们的服务设置每秒请求数智慧 API 最多 100 次，多了就等待。
	- Flink 会推一大堆指标给 Go Proxy，需要进行数据清洗，过滤掉非业务指标再推给数智慧。
	  collapsed:: true
		- **解决方案：**
			- **原则：**为了高性能，过滤逻辑必须在内存中完成，指标白名单也必须存到内存里，并且这个内存中的指标白名单可以被动态更新而无需重启服务。
			- **存在哪？**Go 的 `map`  + 配置中心。
			- **`map` 里的数据从哪来？**
				- 把要监测的指标列表作为一个 `yaml` 配置文件存在配置中心（Nacos）。
				- **启动时：**在 Kratos 服务启动时，就从配置中心读取这个“指标白名单”加载到 `map` 中。
				- **变更时：**Kratos 可以监听配置中心的更新，当配置中心上的指标白名单更新时，会主动推送一个变更事件给 Kratos 服务，服务收到之后替换掉内存中的旧 `map`。
- ## 注意
	- 禁止透传数智慧的 API 格式，需定义自有接口规范，便于未来替换成其它的告警分析系统。
	  logseq.order-list-type:: number
	- Go Proxy 服务支持分布式扩容。
	  logseq.order-list-type:: number
- ## 数智慧平台
	- **定义：**它不是一个基于“固定阈值”的告警系统，而是一个基于历史值、自学习的异常检测平台。
	- **解决痛点：**它的目标是自动过滤掉“无效告警”，只把真正的异常报出来。
	- **自动计算的核心变量：**
		- 这是整个智能检测的基础，系统会为每条指标曲线自动计算出“历史画像”，调优人员必须深刻理解这三个值的含义。
		- **基线值：**
			- **是什么：**一个“可信的历史平均值” 。
			- **怎么算：**系统为曲线上每个时间点（分钟粒度），拉取过去8天同一时刻的数据作为样本 。在计算“均值”的过程中，会根据样本密度分布，自动去除离群点（历史上的异常）。
		- **CV（置信系数）：**
			- **是什么：**该时间点在历史上的“波动剧烈程度”或“离散程度”，是基线值的“可信度”。
			- **怎么算：**使用与基线值相同的8天历史样本。
				- **CV值小：**说明历史数据很集中、很稳定。
				- **CV值大：**说明历史数据很分散、爱折腾。
		- **峰值：**
			- 平台在计算峰值时，首要目标是避免“毛刺”（即突然的、不正常的尖峰）的影响。如果直接取历史最大值，那么一个偶然的系统抖动或刷量就可能把“峰值”拉得非常高，导致后续的告警判断（例如“业务低谷”的判断）完全失准。
			- “峰值”基于基线值的统计结果。系统会先计算出曲线中每个时间点（例如一天中的 1440 个分钟点）的基线值，然后再对这 1440 个基线值进行统计，最终得到峰值。
			- **计算方法：去除离群点后取“较高值”**
				- 在全天时段时，去除少数特别高的点，得到曲线在全天时段较高的值。
	- **“量类型”告警逻辑流程：**
		- **[ 第 1 步：峰值过滤 (准入门槛) ]**
			- 系统首先检查该曲线的**“峰值”**（自动计算的业务高峰统计值）。
			- **如果 `峰值 <= 10`：**
				- **判定：**业务量太小，没有检测必要。➡️ 流程结束（不检测）
			- **如果 `峰值 > 10`**：
				- **判定：** 曲线有检测价值。➡️ 进入第 2 步
		- **[ 第 2 步：CV 分流 (波动性判断) ]**
			- **高CV / 爱折腾：**此刻在历史上“波动剧烈”。规则会变得**宽松**。
				- 系统会进一步判断当前是否处于“业务低谷”。如果是低谷期，可能直接不进行检测；如果不是低谷期，则可能需要数据掉到 0 并满足附加条件才会被判定为异常。
				- **A-1. 判断是否“业务低谷”：**
					- 检查 `基线值 <= 峰值的1/4` ？
					- **是（处于低谷）：**判定为“低谷期的正常剧烈波动”。➡️ 流程结束（不告警）
					- **否（非低谷）：**➡️ 进入 A-2。
				- **A-2. 判断是否“掉到0”：**
					- 检查 `当前值 == 0` ？
					- **否（未掉到0）：** 判定为“高波动的正常范围”。➡️ 流程结束（不告警）
					- **是（已掉到0）：** ➡️ 进入 A-3。
				- **A-3. 检查“附加抑制条件”：**
					- **条件1：**过去7天 非0比例 > 0.8（即平时不常掉到0，历史非0值比例高）。
					- **条件2：**掉到0持续时间 > `max(5分钟, 10倍CV分钟)`。
					- **全部满足：**✅ 触发告警
					- **任一不满足：**➡️ 流程结束（不告警）
			- **低CV / 很稳定：**此刻在历史上“表现稳定”。规则会变得**严格**。
				- **B-1. 判断是否“掉到0”：**
					- 检查 `当前值 == 0`？
					- **是（已掉到0）：** ➡️ **进入 B-2 (掉到0的处理)**。
					- **否（未掉到0）：** ➡️ **进入 B-3 (未掉到0的处理，仅下降)**。
				- **B-2. (已掉到0) 按时段检查持续时间：**
					- **情况1：业务低谷（基线值 < 峰值 1/8）**
						- 条件：0 值持续 10 分钟。
						- 满足：✅ 触发告警
					- **情况2：业务次低谷（峰值 1/8 ≤ 基线值 ≤ 峰值 1/4）**
						- 条件：0 值持续时间取决于过去 60 分钟内的掉 0 次数（非周期性，最多 10 分钟）。
						- 满足：✅ 触发告警
					- **情况3：正常时段（基线值 > 峰值 1/4）**
						- 条件：直接报出（或持续时间很短）。
						- 满足：✅ 触发告警
				- **B-3.（未掉到 0）检查下降幅度和持续时间：**
					- **门槛条件：需同时满足以下三项：**
						- **下降比例 > 0.25**
							- **什么意思？** 下降幅度必须**至少超过25%**。如果只是从1000掉到950（只掉了5%），系统会认为这是无意义的毛刺，直接放行（不告警）。
						- **下降比例 > 3 × CV**
							- **什么意思？**它要求下降的幅度必须显著大于它“平时的正常波动”。
							- **举例：**
								- **A曲线（很稳）：** CV=0.02 (即平时波动2%)。突然下降了25%。
									- 25% 远大于 3倍CV (6%)。**通过！**
								- **B曲线（有点波折）：** CV=0.1 (即平时波动10%)。也下降了25%。
									- 25% 并未远大于 3倍CV (30%)。**不通过！**
							- **目的：** 自动过滤掉那些“虽然下降了25%，但对于它爱波动的个性来说很正常”的抖动。
						- **下降幅度 > 20**
							- **什么意思？** 这是一个“防小基线”的保险。它要求下降的**绝对值**必须大于20。
							- **举例：** 假设基线值很小，只有40。突然掉到了20。
								- 比例上看，下降了50%，满足`> 0.25`。
								- CV也很小，满足 `> 3倍CV`。
								- **但是**，`下降幅度` 只是20 (`40-20=20`)，没有**大于**20。**不通过！**
							- **目的：** 防止在基线值很小的时候（如40、50），一点点绝对值的下降（掉10、20）就因为百分比很大而触发告警。
					- **若未满足以上条件：➡️ 流程结束（不告警）**
						- 只有**同时满足**这三个“门槛”条件（降幅够大、降幅远超平时波动、且绝对值也够大），系统才会认为这是一个“**可疑的异常**”，并进入第3道关卡。
					- **若满足条件，则按下降幅度分层检查持续时间：**
						- 系统会把下降比例分为“大、中、小”三档：
							- 大降（> 0.75）：持续 2 分钟 ➡️ ✅ 触发告警
							- 中降（0.5～0.75）：持续 3 分钟 ➡️ ✅ 触发告警
							- 小降（0.25～0.5）：持续 5 分钟，且必须为**突变型下降**（缓慢下降不报）➡️ ✅ 触发告警
		- **第三层 (时段分流)：**`基线值` 在什么水平？
			- 系统会用基线值和峰值的比例（如 1/4分位、1/8分位）来判断当前是“业务低谷”还是“正常时段”。
			- **低谷时段：** 规则宽松，可能只关心“是否掉到0”。
			- **正常时段：** 规则严格，会计算“下降比例”和“下降幅度”，并同时要求下降值**大于CV的倍数**（如 > 3CV）。
		- **第四层 (持续时间过滤)：**
			- 为了避免因短暂波动导致的误报，系统要求异常情况必须**持续一段时间**后才会被报出。
			- 这个时间是分层的：下降越大，持续时间要求越短（如大降 > 75% 持续2分钟，小降 25-50% 持续5分钟）。
		- **防抖动机制 (首次 vs 持续)：**
			- 算法区分了“首次报出的条件”和“告警持续的条件” 。“首次”触发的条件更严格，“持续”的条件更宽松。
			- “宽松”在这里的意思是：**“更容易满足”**或**“门槛更低”**。一旦告警被触发后，系统会立刻切换到一个“更容易满足”的（宽松的）门槛来维持这个告警。这是为了防止告警在“临界值”附近被频繁触发和恢复。
			- **举例：**
				- **场景1：严格的“首次”触发**
					- **条件：** `油量 < 50公里`（这是“严格”的，门槛高）
					- **动作：** 告警灯**亮起**。
				- **场景2：如果“持续”条件 *不* 宽松（错误的设计）**
					- **“持续”条件（错的）：** 告警灯保持亮起的条件 *也是* `油量 < 50公里`。
					- **问题（抖动）：** 您开上了一个斜坡，油箱里的油晃了一下，传感器瞬间读到“剩余51公里”。
						- 掉到 49 -> 告警**响**！
						- 晃到 51 -> 告警**停**！
						- 掉到 49 -> 告警又**响**！
						- 晃到 51 -> 告警又**停**！
					- **结果：** 告警在临界点上“疯狂抖动”，这就是“告警抖动”。
				- **防抖动机制：**
					- 为了解决这个问题，系统设置了一个“宽松”的恢复条件。
					- **规则是：** 一旦灯亮了（首次触发），它会**保持点亮**（告警持续），直到您去加了油，油量**明显超过**一个“安全线”（比如“**剩余80公里**”）时，灯才会**熄灭**（告警恢复）。
-