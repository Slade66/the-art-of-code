## 需求分析
	- **需求产生原因：**智能告警平台没有 AI 分析功能，我们要给它增加 AI 分析的功能，因此我们要嵌入数智慧AIOps 系统。
	- **数据的流转逻辑：**
		- Telegraf 把原始的指标数据推送给 Kafka，Flink 从 Kafka 中抓取数据然后推送给 Go Proxy，Go Proxy 再推送给数智慧让它进行分析，数智慧会产生告警和趋势：
			- Go Proxy 要轮询数智慧有没有产生告警，然后推送给智能告警平台展示。
			- 智能告警平台要从数智慧获取趋势。
	- **要集成的数智慧页面：**
		- 指标全局视图（趋势）。
		- 异常检测配置（配置规则条件，根据预测的规则产生告警）。
		- 告警管理（当前告警、历史告警）。
	- **要实现的功能：**
		- 控制哪些 Flink 发来的指标要转发给数智慧（指标管理）。
		- 轮询数智慧的告警，有就推给智能告警系统。
- ## 难点
	- 逆向分析数智慧 AIOps 系统的接口。
	  logseq.order-list-type:: number
	  collapsed:: true
		- 在浏览器 F12 的 Network 页签下，每当你在页面上做一件事（点击某个按钮），就去观察新出现的 API 请求，然后立刻在 Apifox 中复现它，并把它保存在 Apifox 中。
		- 在过滤器 (Filter) 里，勾选 `Fetch/XHR`。这会帮你过滤掉所有图片、CSS、JS 等静态资源，只看 API 请求。
		- 当你把这三个页面的核心 API——获取趋势、CRUD 规则、查询告警——全部在 Apifox 里成功复现并调通后，你的阶段二就胜利完成了。
		- **如何鉴权：**
			- 随便点击一个页面功能，找到一个 API 请求，在它的 `Request Headers` (请求头) 里找到鉴权信息。
			- 这通常是一个 `Authorization: Bearer ...` (JWT Token) 或者是一个 `Cookie`。
			- **关键一步：**在 Apifox 中，把这个 `Authorization` 或 `Cookie` 配置到环境的 Header 里，这样 Apifox 才能模拟你“已登录”的身份去请求 API。
		- **使用 cURL 导入：**
			- 在 F12 Network 里，右键点击一个你分析的请求，选择 `Copy` -> `Copy as cURL (bash)`。
			- 在 Apifox 里，点击“导入”，粘贴 cURL。Apifox 会自动帮你填好 URL、Method、Header、Body。这是最快的方法，连 `Authorization` 都帮你带过来了。
	- Flink 的流量很大，会把 Go Proxy 推死，也会把数智慧推死。
	  logseq.order-list-type:: number
	  collapsed:: true
		- **解决方案：**
			- **原则：**在 Flink 和 Go 服务之间，不能直接调用。不要让高吞吐量的流式系统直接调用一个 API 服务。
			- **转变架构：**Flink 不再直接调 Go Proxy，Go 服务从被动接受者变为 Kafka 的消费者，按照自己的节奏去 Kafka 消费数据，从而完全控制了对下游的压力。
			- **更进一步：把过滤的任务交给 Flink：**Flink 去配置中心拉取指标白名单，在处理 Kafka 的数据时，在内存中实时进行过滤，然后推送已过滤的数据到新的 Kafka Topic，Go Proxy 从新的 Topic 中读取数据。
			- **不能这么做：**Flink 的职责耦合。而且 Kafka 和 Flink 本身就削峰了，我们只能保证流量不被突然的无法预测的高峰冲垮，但是平时的正常流量都顶不住那就是数智慧的问题了。Flink 过滤过于占用内存。
			- **多维度降压：**
				- **减少对数智慧 API 的调用（批处理）：**Go 一次从 Kafka 拉取一大批数据进行处理，然后只发起一次 HTTP 请求，用一个网络请求提交批量数据。
				- **把指标粒度从秒级变为分钟级（窗口聚合）：**分析告警和预测趋势真的需要每秒的指标吗？用分钟级的指标能否预测出同样的效果？这样可以先用窗口函数对原始指标做聚合，降低发给数智慧的数据量。
					- **不能这么做：**但是降低数据的粒度，会导致告警的时间准确度下降，可能会延后产生告警信息。
				- **限流器：**Go 服务在每一次调用数智慧的 API 之前，都必须经过一个限流器，比如我们的服务设置每秒请求数智慧 API 最多 100 次，多了就等待。
	- Flink 会推一大堆指标给 Go Proxy，需要进行数据清洗，过滤掉非业务指标再推给数智慧。
	  logseq.order-list-type:: number
	  collapsed:: true
		- **解决方案：**
			- **原则：**为了高性能，过滤逻辑必须在内存中完成，指标白名单也必须存到内存里，并且这个内存中的指标白名单可以被动态更新而无需重启服务。
			- **存在哪？**Go 的 `map`  + 配置中心。
			- **`map` 里的数据从哪来？**
				- 把要监测的指标列表作为一个 `yaml` 配置文件存在配置中心（Nacos）。
				- **启动时：**在 Kratos 服务启动时，就从配置中心读取这个“指标白名单”加载到 `map` 中。
				- **变更时：**Kratos 可以监听配置中心的更新，当配置中心上的指标白名单更新时，会主动推送一个变更事件给 Kratos 服务，服务收到之后替换掉内存中的旧 `map`。
- ## 注意
	- 需和武哥明确需推送的具体指标，避免全量数据推送（大量非必要的指标）。
	  logseq.order-list-type:: number
	- 禁止透传数智慧的 API 格式，需定义自有接口规范，便于未来替换成其它的告警分析系统。
	  logseq.order-list-type:: number
	- Go Proxy 服务支持分布式扩容。
	  logseq.order-list-type:: number
- ## 需要开会明确
	- `Nacos` 里那份 `metrics-allowlist.yaml`。
-